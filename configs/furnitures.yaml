# logger options
image_save_iter: 2000         # How often do you want to save output images during training
#image_display_iter: 100       # How often do you want to display output images during training
h_scale: 1                    # scale the w/h ratio when save images
w_scale: 1                    # scale the w/h ratio when save images
display_size: 10               # How many images do you want to display each row
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats

# optimization options
max_iter: 300000              # maximum number of training iterations, qss
batch_size: 8                # batch size, qss
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter, qss 0.5 or 0.0
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate, qss 0.0001/0.0002
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate, qss
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss, qss
recon_x_w: 10                  # weight of image reconstruction loss, qss
recon_s_w: 1                  # weight of style reconstruction loss, qss
recon_c_w: 1                  # weight of content reconstruction loss, qss
dist_w: 1.0                     # weight of nested distribution loss, qss
maha_w: 1.0
tv_w: 0.1                       # weight of total variation loss, qss [<10?]
local_cls: False
style_adv: False
cycle_entropy: True

# model options
gen:
  travel_gan: False
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 8                # length of style code, qss
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder, qss
  n_res: 3                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
  alpha: 20.0                # energy threshold in divergence computing for nested distributions, qss
  m: 200.0                   # margin in for distinguishing negative nested distributions, qss
  tree: [2, 3, 3, 1, 2]       # qss

dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln], qss snXX ?
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D, qss
  gan_type: lsgan             # GAN loss [lsgan/nsgan/wgan-gp], qss
  num_scales: 3               # number of scales, qss
  pad_type: reflect           # padding type [zero/reflect]
  tree: [2, 3, 3, 1, 2]
  multi_adv: False

# data options
input_dim: 3                                # number of image channels [1/3]
num_workers: 3                              # number of data loading threads
new_size: 128                               # first resize the shortest image side to this size, qss
crop_image_height: 128                      # random crop image of this height, qss
crop_image_width: 128                       # random crop image of this width, qss

model_name: furnitures                                                             # model name of each try, qss
data_folder: /home/qiaoshishi/datasets/shapenet_view45/                            # data root folder, qss
train_list_file: train.txt                                                         # train txt file name, qss
test_list_file: test.txt                                                           # test txt file name , qss
filter_labels: [15, 16, 19, 20, 25, 26]
