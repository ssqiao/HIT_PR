# logger options
image_save_iter: 2000         # How often do you want to save output images during training
#image_display_iter: 100       # How often do you want to display output images during training
h_scale: 1                    # scale the w/h ratio when save images
w_scale: 1                    # scale the w/h ratio when save images
display_size: 10               # How many images do you want to display each row
snapshot_save_iter: 20000     # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats

# optimization options
max_iter: 300000              # maximum number of training iterations, qss
batch_size: 16                # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter, qss 0.5 or 0.0
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate, qss 0.0001/0.0002 or asynchronous lr
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate, qss
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 1                  # weight of content reconstruction loss, qss
dist_w: 1                     # weight of nested distribution loss, qss [?]
maha_w: 1.                    # weight of mahalanobis distance of encoded style to its distribution(s), qss [?]
tv_w: 0.1                     # weight of total variation loss, qss [?]
local_cls: False
style_adv: False
cycle_entropy: False

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 8                # length of style code, qss [?]
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder, qss
  n_res: 3                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
  alpha: 50.0                # energy threshold in divergence computing for nested distributions, qss [?]
  m: 200.0                   # margin in for distinguishing negative nested distributions, qss [?]
  tree: [4, 3, 3, 3, 3, 2, 2, 2]       # qss

dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln], qss snXX [?]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan/wgan-gp]
  num_scales: 3               # number of scales, qss
  pad_type: reflect           # padding type [zero/reflect]
  tree: [4, 3, 3, 3, 3, 2, 2, 2]       # qss
  multi_adv: False

# data options
input_dim: 3                                # number of image channels [1 or 3]
num_workers: 8                              # number of data loading threads
new_size: 128                               # first resize the shortest image side to this size, qss
crop_image_height: 178                      # random crop image of this height, qss
crop_image_width: 178                       # random crop image of this width, qss

model_name: celeba                                                                # model name of each try, qss
data_folder: /home/ouc/data1/qiaoshishi/datasets/CelebA/img_align_celeba/               # data root folder, qss
train_list_file: train.txt                                                         # train txt file name, qss
test_list_file: test.txt                                                           # test txt file name , qss
filter_labels: []
