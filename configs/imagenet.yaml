# logger options
image_save_iter: 5000         # How often do you want to save output images during training
#image_display_iter: 100       # How often do you want to display output images during training
h_scale: 1                    # scale the w/h ratio when save images
w_scale: 1                    # scale the w/h ratio when save images
display_size: 10               # How many images do you want to display each row
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats

# optimization options
max_iter: 500000              # maximum number of training iterations, qss
batch_size: 8                # batch size, qss
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter, qss 0.5 or 0.0
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate, qss 0.0001/0.0002
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate, qss
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss, qss
recon_x_w: 10                 # weight of image reconstruction loss, qss
recon_s_w: 1                  # weight of style reconstruction loss, qss
recon_c_w: 1                  # weight of content reconstruction loss, qss
dist_w: 1                     # weight of nested distribution loss, qss
maha_w: 1
tv_w: 0                       # weight of total variation loss, qss [<10?]
local_cls: False
style_adv: False
cycle_entropy: True
# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 8                # length of style code, qss
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder, StarGAN-v2 (4 for content, 6 for style encoder 256*256) qss
  n_res: 3                    # number of residual blocks in content encoder/decoder, MUNIT (4 for 256*256)
  pad_type: reflect           # padding type [zero/reflect]
  alpha: 50.0                # energy threshold in divergence computing for nested distributions, qss #
  m: 200.0                   # margin in for distinguishing negative nested distributions, qss #
  tree: [3, 4, 4, 4, 1, 3]   #[3, 4, 4, 4, 1, 3]       # qss #

dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln], qss snXX ?
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D, StarGAN-v2 (6 for 256*256) qss
  gan_type: lsgan             # GAN loss [lsgan/nsgan/wgan-gp]
  num_scales: 3               # number of scales, qss
  pad_type: reflect           # padding type [zero/reflect]
  tree: [3, 4, 4, 4, 1, 3]       # qss #
  multi_adv: False            # qss

# data options
input_dim: 3                                # number of image channels [1/3]
num_workers: 3                              # number of data loading threads
new_size: 128                               # first resize the shortest image side to this size, qss
crop_image_height: 128                      # random crop image of this height, qss
crop_image_width: 128                       # random crop image of this width, qss

# TODO QIAO
model_name: imagenet                    # model name of each try, qss
data_folder: /home/ouc/data1/qiaoshishi/datasets/imageNet_translation/               # data root folder, qss
train_list_file: train_crop_easy.txt                                                         # train txt file name, qss
test_list_file: val_crop_easy.txt                                                           # test txt file name , qss
filter_labels: [5, 6, 7, 8, 0, 1, 2, 4, 11, 13, 14, 15] #[5, 6, 7, 8, 0, 1, 2, 4, 11, 13, 14, 15]
